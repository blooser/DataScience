{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"sms1.tsv\", delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "6       Even my brother is not like to speak with me. ...\n",
       "7       As per your request 'Melle Melle (Oru Minnamin...\n",
       "8       WINNER!! As a valued network customer you have...\n",
       "9       Had your mobile 11 months or more? U R entitle...\n",
       "10      I'm gonna be home soon and i don't want to tal...\n",
       "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12      URGENT! You have won a 1 week FREE membership ...\n",
       "13      I've been searching for the right words to tha...\n",
       "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15      XXXMobileMovieClub: To use your credit, click ...\n",
       "16                             Oh k...i'm watching here:)\n",
       "17      Eh u remember how 2 spell his name... Yes i di...\n",
       "18      Fine if thats the way u feel. Thats the way ...\n",
       "19      England v Macedonia - dont miss the goals/team...\n",
       "20              Is that seriously how you spell his name?\n",
       "21        I‘m going to try for 2 months ha ha only joking\n",
       "22      So ü pay first lar... Then when is da stock co...\n",
       "23      Aft i finish my lunch then i go str down lor. ...\n",
       "24      Ffffffffff. Alright no way I can meet up with ...\n",
       "25      Just forced myself to eat a slice. I'm really ...\n",
       "26                         Lol your always so convincing.\n",
       "27      Did you catch the bus ? Are you frying an egg ...\n",
       "28      I'm back &amp; we're packing the car now, I'll...\n",
       "29      Ahhh. Work. I vaguely remember that! What does...\n",
       "                              ...                        \n",
       "5542             Armand says get your ass over to epsilon\n",
       "5543               U still havent got urself a jacket ah?\n",
       "5544    I'm taking derek &amp; taylor to walmart, if I...\n",
       "5545        Hi its in durban are you still on this number\n",
       "5546           Ic. There are a lotta childporn cars then.\n",
       "5547    Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5548                   No, I was trying it all weekend ;V\n",
       "5549    You know, wot people wear. T shirts, jumpers, ...\n",
       "5550          Cool, what time you think you can get here?\n",
       "5551    Wen did you get so spiritual and deep. That's ...\n",
       "5552    Have a safe trip to Nigeria. Wish you happines...\n",
       "5553                          Hahaha..use your brain dear\n",
       "5554    Well keep in mind I've only got enough gas for...\n",
       "5555    Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5556    Yes i have. So that's why u texted. Pshew...mi...\n",
       "5557    No. I meant the calculation is the same. That ...\n",
       "5558                               Sorry, I'll call later\n",
       "5559    if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5560                    Anything lor. Juz both of us lor.\n",
       "5561    Get me out of this dump heap. My mom decided t...\n",
       "5562    Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5563                                  Ard 6 like dat lor.\n",
       "5564    Why don't you wait 'til at least wednesday to ...\n",
       "5565                                         Huh y lei...\n",
       "5566    REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: 1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/blooser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "corpus = []\n",
    "columns = dataset[0].count()\n",
    "for i in range(0, columns):\n",
    "    msg = re.sub(\"[^a-zA-Z]\", \" \", dataset[1][i])\n",
    "    msg = msg.lower()\n",
    "    msg = msg.split()\n",
    "    ps = PorterStemmer()\n",
    "    msg = [ps.stem(word) for word in msg if not word in set(stopwords.words('english'))]\n",
    "    msg = ' '.join(msg)\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_y = LabelEncoder()\n",
    "y = label_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =  RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [10, 100, 200, 300]}]\n",
    "cv = GridSearchCV(estimator=classifier, param_grid=parameters, scoring='accuracy')\n",
    "cv = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 98%\n"
     ]
    }
   ],
   "source": [
    "def percent(value):\n",
    "    return \"{0:.0%}\".format(value)\n",
    "\n",
    "print(\"Best Accuracy: {}\".format(percent(cv.best_score_))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier =  RandomForestClassifier(n_estimators=200, criterion='entropy', random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy = cross_val_score(classifier, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98%\n",
      "Loss: 0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(percent(accuracy.mean())))\n",
    "print(\"Loss: {}\".format(percent(accuracy.std())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[966,   0],\n",
       "       [ 24, 125]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, FN, TN = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "\n",
    "ACC = (TP + TN)/(TP+FP+FN+TN)\n",
    "PPV = TP/(TP+FP)\n",
    "TPR = TP/(TP+FN)\n",
    "F1 = (2*PPV*TPR)/(PPV+TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "name = \"result.csv\"\n",
    "with open(name, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    titles = ['True Positives', 'False Positives', 'False Negatives', \n",
    "              'True Negatives', 'Accuracy', 'Precision', 'Sensitivity',\n",
    "             'F1']\n",
    "    writer.writerow(titles)\n",
    "    values = [TP, FP, FN, TN, percent(ACC), percent(PPV), percent(TPR), percent(F1)]   \n",
    "    writer.writerow(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>125</td>\n",
       "      <td>98%</td>\n",
       "      <td>100%</td>\n",
       "      <td>98%</td>\n",
       "      <td>99%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True Positives  False Positives  False Negatives  True Negatives Accuracy  \\\n",
       "0             966                0               24             125      98%   \n",
       "\n",
       "  Precision Sensitivity   F1  \n",
       "0      100%         98%  99%  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_summary = pd.read_csv('result.csv')\n",
    "total_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
